{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classfication.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qwMjlE1Lmkj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD-00iZ-MQXl"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/data/')\n",
        "train = pd.read_csv('train.csv', encoding = 'utf-8')\n",
        "test = pd.read_csv('test_x.csv', encoding = 'utf-8')\n",
        "sample_submission = pd.read_csv('sample_submission.csv', encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyPNcdynNeLS"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb2oSMDA7qu"
      },
      "source": [
        "train['text'] = train['text'].apply(lambda x: word_tokenize(x))\n",
        "train['words_count'] = train['text'].apply(lambda x: len(x))\n",
        "train['text'] = train['text'].apply(lambda x: ' '.join([s for s in x if s not in stop_words]))\n",
        "train['stop_words_count'] = train['text'].apply(lambda x: len(x))\n",
        "train['numerics'] = train['text'].apply(lambda x : len([s for s in x if s.isdigit()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-I0WW6RWpt3"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4--X_B2z95fi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train.drop(['author','index'],1), train['author'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V1Fmtqm-Q7W"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_vectors = vectorizer.fit_transform(X_train['text'])\n",
        "test_vectors = vectorizer.transform(X_test['text'])\n",
        "print(train_vectors.shape, test_vectors.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN5jRyzg_egj"
      },
      "source": [
        "%%time\n",
        "import lightgbm as lgb\n",
        "\n",
        "dtrain = lgb.Dataset(train_vectors,y_train)\n",
        "dtest = lgb.Dataset(test_vectors,y_test)\n",
        "\n",
        "param_lgb = {\n",
        "    'max_depth': 5,\n",
        "    'learning_rate': 0.33,\n",
        "    'max_bin': 1000,\n",
        "    'num_leaves' : 100,\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 5,\n",
        "    'metric': 'softmax',\n",
        "    'num_iter': 1000\n",
        "    \n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(param_lgb,dtrain,valid_sets=dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EJT3waBEQQG"
      },
      "source": [
        "y_pred = lgb_model.predict(test_vectors)\n",
        "y_argmax = y_pred.argmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ66hdy-GZ0S"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy=accuracy_score(y_test, y_argmax)\n",
        "precision = precision_score(y_test, y_argmax, average='micro')\n",
        "recall = recall_score(y_test, y_argmax, average='micro')\n",
        "f1 = f1_score(y_test, y_argmax, average='micro')\n",
        "print('accuracy:',accuracy,'\\n','precision:',precision,'\\n','recall:',recall,'\\n','f1_score:',f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-F8h7dPKGL7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}