{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classfication.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qwMjlE1Lmkj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD-00iZ-MQXl"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/data/')\n",
        "train = pd.read_csv('train.csv', encoding = 'utf-8')\n",
        "test = pd.read_csv('test_x.csv', encoding = 'utf-8')\n",
        "sample_submission = pd.read_csv('sample_submission.csv', encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyPNcdynNeLS"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8eT0FDfby1r"
      },
      "source": [
        "def cleansing(text):\n",
        "    repl = ''\n",
        "    pattern = '[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, repl, text)\n",
        "    return text\n",
        "\n",
        "train['text'] = train['text'].map(lambda x: cleansing(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb2oSMDA7qu"
      },
      "source": [
        "train['text'] = train['text'].apply(lambda x: word_tokenize(x))\n",
        "train['words_count'] = train['text'].apply(lambda x: len(x))\n",
        "train['text'] = train['text'].apply(lambda x: [s.lower() for s in x if s not in stop_words])\n",
        "train['stop_words_count'] = train['text'].apply(lambda x: len(x))\n",
        "train['numerics'] = train['text'].apply(lambda x : len([s for s in x if s.isdigit()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-I0WW6RWpt3"
      },
      "source": [
        "import collections\n",
        "counter0 = collections.Counter()\n",
        "\n",
        "for tokens in train[train['author']==0]['text']:\n",
        "    counter0.update(tokens)\n",
        "\n",
        "counter0.most_common(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egO96ZgldYKD"
      },
      "source": [
        "import collections\n",
        "counter1 = collections.Counter()\n",
        "\n",
        "for tokens in train[train['author']==1]['text']:\n",
        "    counter1.update(tokens)\n",
        "\n",
        "counter1.most_common(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmiB89uWdX-5"
      },
      "source": [
        "import collections\n",
        "counter2 = collections.Counter()\n",
        "\n",
        "for tokens in train[train['author']==2]['text']:\n",
        "    counter2.update(tokens)\n",
        "\n",
        "counter2.most_common(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_cUGbTddXz7"
      },
      "source": [
        "import collections\n",
        "counter3 = collections.Counter()\n",
        "\n",
        "for tokens in train[train['author']==3]['text']:\n",
        "    counter3.update(tokens)\n",
        "\n",
        "counter3.most_common(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF0SRgS7dXo5"
      },
      "source": [
        "import collections\n",
        "counter4 = collections.Counter()\n",
        "\n",
        "for tokens in train[train['author']==4]['text']:\n",
        "    counter4.update(tokens)\n",
        "\n",
        "counter4.most_common(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4--X_B2z95fi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train.drop(['author','index'],1), train['author'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V1Fmtqm-Q7W"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_vectors = vectorizer.fit_transform(X_train['text'])\n",
        "test_vectors = vectorizer.transform(X_test['text'])\n",
        "print(train_vectors.shape, test_vectors.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN5jRyzg_egj"
      },
      "source": [
        "%%time\n",
        "import lightgbm as lgb\n",
        "\n",
        "dtrain = lgb.Dataset(train_vectors,y_train)\n",
        "dtest = lgb.Dataset(test_vectors,y_test)\n",
        "\n",
        "param_lgb = {\n",
        "    'max_depth': 5,\n",
        "    'learning_rate': 0.33,\n",
        "    'max_bin': 1000,\n",
        "    'num_leaves' : 100,\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 5,\n",
        "    'metric': 'softmax',\n",
        "    'num_iter': 1000\n",
        "    \n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(param_lgb,dtrain,valid_sets=dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EJT3waBEQQG"
      },
      "source": [
        "y_pred = lgb_model.predict(test_vectors)\n",
        "y_argmax = y_pred.argmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ66hdy-GZ0S"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy=accuracy_score(y_test, y_argmax)\n",
        "precision = precision_score(y_test, y_argmax, average='micro')\n",
        "recall = recall_score(y_test, y_argmax, average='micro')\n",
        "f1 = f1_score(y_test, y_argmax, average='micro')\n",
        "print('accuracy:',accuracy,'\\n','precision:',precision,'\\n','recall:',recall,'\\n','f1_score:',f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-F8h7dPKGL7"
      },
      "source": [
        "lgb.plot_importance(lgb_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_31op8bREN6"
      },
      "source": [
        "%%time\n",
        "import lightgbm as lgb\n",
        "\n",
        "dtrain = lgb.Dataset(train_vectors,y_train)\n",
        "dtest = lgb.Dataset(test_vectors,y_test)\n",
        "\n",
        "param_lgb = {\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.33,\n",
        "    'max_bin': 1000,\n",
        "    'num_leaves' : 256,\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 5,\n",
        "    'metric': 'softmax',\n",
        "    'num_iter': 1000\n",
        "    \n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(param_lgb,dtrain,valid_sets=dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvJUmmNNU5Zd"
      },
      "source": [
        "y_pred = lgb_model.predict(test_vectors)\n",
        "y_argmax = y_pred.argmax(1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy=accuracy_score(y_test, y_argmax)\n",
        "precision = precision_score(y_test, y_argmax, average='micro')\n",
        "recall = recall_score(y_test, y_argmax, average='micro')\n",
        "f1 = f1_score(y_test, y_argmax, average='micro')\n",
        "print('accuracy:',accuracy,'\\n','precision:',precision,'\\n','recall:',recall,'\\n','f1_score:',f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGquOjyfU_9W"
      },
      "source": [
        "%%time\n",
        "import lightgbm as lgb\n",
        "\n",
        "dtrain = lgb.Dataset(train_vectors,y_train)\n",
        "dtest = lgb.Dataset(test_vectors,y_test)\n",
        "\n",
        "param_lgb = {\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.33,\n",
        "    'max_bin': 1000,\n",
        "    'num_leaves' : 512,\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 5,\n",
        "    'metric': 'softmax',\n",
        "    'num_iter': 1000\n",
        "    \n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(param_lgb,dtrain,valid_sets=dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U0plviLVXxv"
      },
      "source": [
        "y_pred = lgb_model.predict(test_vectors)\n",
        "y_argmax = y_pred.argmax(1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy=accuracy_score(y_test, y_argmax)\n",
        "precision = precision_score(y_test, y_argmax, average='micro')\n",
        "recall = recall_score(y_test, y_argmax, average='micro')\n",
        "f1 = f1_score(y_test, y_argmax, average='micro')\n",
        "print('accuracy:',accuracy,'\\n','precision:',precision,'\\n','recall:',recall,'\\n','f1_score:',f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPQbOdk0VYUG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}